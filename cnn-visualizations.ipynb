{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Filter and Feature Visualization \n",
    "\n",
    "This notebook outlines various methods for looking at filters and feature maps in CNN models. I think visually, so this is really meant to help me understand what is going on under the hood. I hope you find it useful as well. \n",
    "\n",
    "**Note:** I've included a `/helper_functions.py` file in the `/src` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "Here we will load a pretrained model from Pytorch. We will be using the VGG16 model in evaluation mode. Let's print the model to take a look at the various layers. The model has three children:\n",
    "* features\n",
    "* avgpool\n",
    "* classifier\n",
    "\n",
    "It is the features that we are interested in extracting weights from. Essentially, these weights in the Conv2d layers make up the filters that will pass over each image during a forward pass through the network. Let's take a look at the model and each filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights, conv_layers = [], []\n",
    "features = model.features\n",
    "conv_counter = 0\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if type(features[i]) == nn.Conv2d:\n",
    "        conv_counter += 1\n",
    "        model_weights.append(features[i].weight)\n",
    "        conv_layers.append(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Layers\n",
    "\n",
    "I'll print out each convolutional layer to take a look at the depth and tensor size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer 1: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([64, 3, 3, 3])\n",
      "Conv layer 2: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([64, 64, 3, 3])\n",
      "Conv layer 3: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([128, 64, 3, 3])\n",
      "Conv layer 4: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([128, 128, 3, 3])\n",
      "Conv layer 5: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([256, 128, 3, 3])\n",
      "Conv layer 6: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([256, 256, 3, 3])\n",
      "Conv layer 7: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([256, 256, 3, 3])\n",
      "Conv layer 8: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([512, 256, 3, 3])\n",
      "Conv layer 9: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([512, 512, 3, 3])\n",
      "Conv layer 10: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([512, 512, 3, 3])\n",
      "Conv layer 11: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([512, 512, 3, 3])\n",
      "Conv layer 12: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([512, 512, 3, 3])\n",
      "Conv layer 13: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) --> Shape: torch.Size([512, 512, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for i, (weights, layers) in enumerate(zip(model_weights, conv_layers)):\n",
    "    print('Conv layer {}: {} --> Shape: {}'.format(i+1, layers, weights.shape))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "\n",
    "Looking at the first filter in Conv layer 1 (`model_weights[idx of conv layer][idx of the filter]`) we can see that it has a `kernel_size = (3, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5537,  0.1427,  0.5290],\n",
       "         [-0.5831,  0.3566,  0.7657],\n",
       "         [-0.6902, -0.0480,  0.4841]],\n",
       "\n",
       "        [[ 0.1755,  0.0099, -0.0814],\n",
       "         [ 0.0441, -0.0703, -0.2604],\n",
       "         [ 0.1324, -0.1728, -0.1323]],\n",
       "\n",
       "        [[ 0.3130, -0.1659, -0.4275],\n",
       "         [ 0.4752, -0.0827, -0.4870],\n",
       "         [ 0.6320,  0.0193, -0.2775]]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 10])\n",
    "model_weights[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(features[0].out_channels)\n",
    "out_channels = features[5].out_channels\n",
    "print(int(np.sqrt(out_channels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 64 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 340,
       "width": 348
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_filter(layer=1, size=6, row=8, col=8):\n",
    "    \"\"\" Print function that prints the filters of a selected \n",
    "        convolutional layer. \n",
    "        \n",
    "        Arguments:\n",
    "            - layer (int) conv layer\n",
    "            - size (int) x, y dim of plot\n",
    "            - row, col (int) row and column width of plot\n",
    "        Returns:\n",
    "            - saved image (.jpg)\n",
    "            - plt.show()\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=[size, size])\n",
    "    for i, filt in enumerate(model_weights[layer-1]):\n",
    "        plt.subplot(row, col, i+1)\n",
    "        plt.imshow(filt[0,:,:].detach(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig('conv_layer_{}.jpg'.format(layer))\n",
    "    plt.show()\n",
    "    \n",
    "plot_filter(1, 6, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
